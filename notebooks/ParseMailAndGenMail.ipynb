{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.output_parsers import PydanticOutputParser, OutputFixingParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from prompts import SYSTEM_MESSAGE, HUMAN_MESSAGE_EXT_DATA, EMAIL_CONTENT_SAMPLE, HUMAN_MESSAGE_GEN_MAIL, all_info_ext_req\n",
    "from data_class import AllInfo, AGT, Customer\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "dotenv_path = os.path.join('../.env')\n",
    "load_dotenv(dotenv_path)\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENAI_MODEL = os.environ.get(\"OPENAI_MODEL\")\n",
    "print(\"using model:\", OPENAI_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info_parser = PydanticOutputParser(pydantic_object=AllInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt_templ = SystemMessagePromptTemplate.from_template(SYSTEM_MESSAGE)\n",
    "ext_data_human_message_templ = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=HUMAN_MESSAGE_EXT_DATA,\n",
    "        input_variables=[\"email_content\", \"request\"],\n",
    "        partial_variables={\"format_instructions\": all_info_parser.get_format_instructions()}\n",
    "    )\n",
    ")\n",
    "ext_data_chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt_templ, ext_data_human_message_templ])\n",
    "ext_data_chain = LLMChain(llm=ChatOpenAI(model_name=OPENAI_MODEL), prompt=ext_data_chat_prompt)\n",
    "\n",
    "gen_mail_human_message_templ = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=HUMAN_MESSAGE_GEN_MAIL,\n",
    "        input_variables=[\"email_content\", \"lacked_info\"],\n",
    "    )\n",
    ")\n",
    "gen_mail_chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt_templ, gen_mail_human_message_templ])\n",
    "gen_mail_chain = LLMChain(llm=ChatOpenAI(model_name=OPENAI_MODEL), prompt=gen_mail_chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_none_attributes(instance):\n",
    "    none_attributes = {}\n",
    "    for field in instance.__fields__:\n",
    "        value = getattr(instance, field)\n",
    "        if value is None:\n",
    "            none_attributes[field] = None\n",
    "        elif isinstance(value, (AGT, Customer)):\n",
    "            none_attrs = list_none_attributes(value)\n",
    "            none_attributes[field] = none_attrs\n",
    "    return none_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s-shiinoki/Library/Caches/pypoetry/virtualenvs/pj-xps-trvint-app-q11VC4XD-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "all_ext_data_chain = SequentialChain(chains=[ext_data_chain], input_variables=[\"email_content\", \"request\"], verbose=True)\n",
    "ext_data_ans = all_ext_data_chain({'email_content':EMAIL_CONTENT_SAMPLE, 'request':all_info_ext_req})\n",
    "out = ext_data_ans['text'].replace(\"None\", \"null\")\n",
    "fix_parser = OutputFixingParser.from_llm(parser=all_info_parser, llm=ChatOpenAI(model_name=OPENAI_MODEL))\n",
    "ext_data = fix_parser.parse(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from customer information:\n",
      "- first_name\n",
      "- family_name\n",
      "- nationality\n",
      "- relationships_between_customers\n",
      "- budget\n",
      "- first_time_visitor\n",
      "- preferences_in_cities\n",
      "- areas_of_interests\n",
      "- accommodations\n",
      "- transportation\n",
      "- guide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "none_attributes = list_none_attributes(ext_data)\n",
    "\n",
    "\n",
    "def create_none_attr_list_str(none_attributes):\n",
    "    output = ''\n",
    "    if len(none_attributes['intermediate_company_info']):\n",
    "        output += 'from intermediate company information:\\n'\n",
    "        for k in none_attributes['intermediate_company_info'].keys():\n",
    "            output += f'- {k}\\n'\n",
    "    if len(none_attributes['customer_info']):\n",
    "        output += 'from customer information:\\n'\n",
    "        for k in none_attributes['customer_info'].keys():\n",
    "            output += f'- {k}\\n'\n",
    "    return output\n",
    "\n",
    "none_str = create_none_attr_list_str(none_attributes)\n",
    "print(none_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Subject: Missing Information Required for Travel Inquiry\n",
      "\n",
      "Dear Estelle Torp,\n",
      "\n",
      "I hope this email finds you well. Thank you for reaching out regarding the upcoming travel booking for a family trip to Japan from May 20th to June 4th.\n",
      "\n",
      "In order to provide the best possible travel experience for your clients, I kindly request the following missing information:\n",
      "\n",
      "1. First Name and Family Name of the travelers\n",
      "2. Nationality of the travelers\n",
      "3. Relationships between the customers (e.g., family, friends)\n",
      "4. Budget for the trip\n",
      "5. Is this the family's first time visiting Japan?\n",
      "6. Preferences in cities to visit\n",
      "7. Areas of interests or specific attractions they would like to explore\n",
      "8. Preferred accommodations (e.g., hotels, ryokans)\n",
      "9. Transportation preferences within Japan\n",
      "10. Need for a guide or any specific language requirements\n",
      "\n",
      "Having this information will allow us to tailor the travel itinerary to meet the specific needs and preferences of the travelers. Your prompt response regarding these details would be greatly appreciated to ensure a seamless planning process.\n",
      "\n",
      "Thank you for your cooperation, and I look forward to assisting you further with this travel inquiry.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Koji\n"
     ]
    }
   ],
   "source": [
    "all_gen_mail_chain = SequentialChain(chains=[gen_mail_chain], input_variables=[\"email_content\", \"lacked_info\"], verbose=True)\n",
    "gen_mail_ans = all_gen_mail_chain({'email_content':EMAIL_CONTENT_SAMPLE, 'lacked_info': none_str})\n",
    "generated_mail = gen_mail_ans['text']\n",
    "print(generated_mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pj-xps-trvint-app-q11VC4XD-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
